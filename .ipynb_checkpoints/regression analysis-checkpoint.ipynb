{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%Import and data manipulation code\n"
    }
   },
   "outputs": [],
   "source": [
    "import functions as f\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "from itertools import product\n",
    "# from tqdm import tqdm_notebook\n",
    "import math\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from pylab import rcParams\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters()\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tools.eval_measures import rmse, aic\n",
    "\n",
    "df = f.openfile('data.h5')\n",
    "\n",
    "'''I thought a dict with all the data per decade would be more useful for you so I went ahead and created that for you'''\n",
    "\n",
    "df['year'] = df['year'].apply(lambda x: int(x.year))\n",
    "\n",
    "decades = df['year'].unique()\n",
    "dataframes = {}\n",
    "for decade in decades:\n",
    "    data = df.loc[(df['year'] == decade)]\n",
    "    dataframes.update({decade: data})\n",
    "\n",
    "# all data , remove column year and country\n",
    "df_num = df.drop(columns=['year', 'country'])\n",
    "\n",
    "# time series data, without countries\n",
    "df_time = df.drop(columns=['country'])\n",
    "AFG = df.loc[(df['country'] == 'AFG')].sort_values(\n",
    "    by='year')\n",
    "cron = df.sort_values(by='year')\n",
    "cron['year'] = cron['year'].apply(lambda x: str(x))\n",
    "df['year'] = df['year'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we import all necessary functions and do some data manipulation to make sure subsequent code runs smoothly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# VAR TESTING START - Vector Auto regression\n",
    "# https://www.machinelearningplus.com/time-series/vector-autoregression-examples-python/\n",
    "# Plot 1 line per country\n",
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, dpi=120, figsize=(10, 6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    data = df[df.columns[i]]\n",
    "    ax.plot(data, color='red', linewidth=1)\n",
    "    # Decorations\n",
    "    ax.set_title(df.columns[i])\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.spines[\"top\"].set_alpha(0)\n",
    "    ax.tick_params(labelsize=6)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# splits  data for train and test (all data)\n",
    "# make country specific by opening line #58, and changing nobe line#85 to 2\n",
    "# again, issue is it looks at everything, not on a country by country basis\n",
    "nobs = 188\n",
    "data = cron[cron.country != 'SRB']\n",
    "data = pd.get_dummies(data.drop(columns=['year']))\n",
    "df_train, df_test = data[0:-nobs], data[-nobs:]\n",
    "\n",
    "\n",
    "def adfuller_test(series, signif=0.05, name='', verbose=False, print=True):\n",
    "    \"\"\"Perform ADFuller to test for Stationarity of given series and print report\"\"\"\n",
    "    r = adfuller(series, autolag='AIC')\n",
    "    output = {'test_statistic': round(r[0], 4), 'pvalue': round(r[1], 4), 'n_lags': round(r[2], 4), 'n_obs': r[3]}\n",
    "    p_value = output['pvalue']\n",
    "\n",
    "    def adjust(val, length=6):\n",
    "        return str(val).ljust(length)\n",
    "\n",
    "    if print:\n",
    "        # Print Summary\n",
    "        print(f'    Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", '-' * 47)\n",
    "        print(f' Null Hypothesis: Data has unit root. Non-Stationary.')\n",
    "        print(f' Significance Level    = {signif}')\n",
    "        print(f' Test Statistic        = {output[\"test_statistic\"]}')\n",
    "        print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n",
    "\n",
    "        for key, val in r[4].items():\n",
    "            print(f' Critical value {adjust(key)} = {round(val, 3)}')\n",
    "\n",
    "        if p_value <= signif:\n",
    "            print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n",
    "            print(f\" => Series is Stationary.\")\n",
    "            return ('stat', p_value)\n",
    "        else:\n",
    "            print(f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n",
    "            print(f\" => Series is Non-Stationary.\")\n",
    "            print('\\n')\n",
    "            return ('non-stat', p_value)\n",
    "    else:\n",
    "        if p_value <= signif:\n",
    "            return 'stat'\n",
    "        else:\n",
    "            return 'non-stat', output['test_statistic']\n",
    "\n",
    "\n",
    "# runs adfuller test for each variable (all data), returns all data stationary\n",
    "# if its ran for each country individually, data is non-stationary...\n",
    "\n",
    "checkup = list()\n",
    "non_stationaries = list()\n",
    "diff = 0\n",
    "\n",
    "for name, column in df_train.iteritems():\n",
    "    res = adfuller_test(column, name=name, print=False)\n",
    "    if res[0] == 'non-stat':\n",
    "        non_stationaries.append({(name + str(diff)): res[1]})\n",
    "\n",
    "df_differenced = df_train\n",
    "\n",
    "while len(non_stationaries) > 0:\n",
    "    checkup.append(non_stationaries)\n",
    "    non_stationaries = list()\n",
    "    diff = diff + 1\n",
    "    df_differenced = df_differenced.diff().dropna()\n",
    "    for name, column in df_differenced.iteritems():\n",
    "        res = adfuller_test(column, name=name, print=False)\n",
    "        if res[0] == 'non-stat':\n",
    "            non_stationaries.append({(name + str(diff)): res[1]})\n",
    "\n",
    "print('final order of differences: ', diff)\n",
    "\n",
    "model = VAR(df_train)\n",
    "try:\n",
    "    for i in range(1, 9):\n",
    "        result = model.fit(i)\n",
    "        print('Lag Order =', i)\n",
    "        print('AIC : ', result.aic)\n",
    "        print('BIC : ', result.bic)\n",
    "        print('FPE : ', result.fpe)\n",
    "        print('HQIC: ', result.hqic, '\\n')\n",
    "except OverflowError:\n",
    "    print('FPE too large, did not want to mess with code in package')\n",
    "\n",
    "model_fitted = model.fit(4)\n",
    "# print(model_fitted.summary())\n",
    "\n",
    "# Get the lag order\n",
    "lag_order = model_fitted.k_ar\n",
    "print(lag_order)  # > 1\n",
    "\n",
    "# Input data for forecasting\n",
    "forecast_input = df_train.values[-lag_order:]\n",
    "\n",
    "fc = model_fitted.forecast(y=forecast_input, steps=nobs)\n",
    "df_forecast = pd.DataFrame(fc, index=data.index[-nobs:], columns=data.columns + '_1d')\n",
    "\n",
    "\n",
    "def invert_transformation(df_train, df_forecast, second_diff=False):\n",
    "    \"\"\"Revert back the differencing to get the forecast to original scale.\"\"\"\n",
    "    df_fc = df_forecast.copy()\n",
    "    columns = df_train.columns\n",
    "    for col in columns:\n",
    "        # Roll back 2nd Diff\n",
    "        if second_diff:\n",
    "            df_fc[str(col) + '_1d'] = (df_train[col].iloc[-1] - df_train[col].iloc[-2]) + df_fc[\n",
    "                str(col) + '_2d'].cumsum()\n",
    "        # Roll back 1st Diff\n",
    "        df_fc[str(col) + '_forecast'] = df_train[col].iloc[-1] + df_fc[str(col) + '_1d'].cumsum()\n",
    "    return df_fc\n",
    "\n",
    "\n",
    "df_results = invert_transformation(df_train, df_forecast)\n",
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(nrows=int(len(data.columns) / 2), ncols=2, dpi=150, figsize=(10, 10))\n",
    "for i, (col, ax) in enumerate(zip(data.columns, axes.flatten())):\n",
    "    df_results[col + '_forecast'].plot(legend=True, ax=ax).autoscale(axis='x', tight=True)\n",
    "    df_test[col][-nobs:].plot(legend=True, ax=ax)\n",
    "    ax.set_title(col + \": Forecast vs Actuals\")\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.spines[\"top\"].set_alpha(0)\n",
    "    ax.tick_params(labelsize=6)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# END OF VAR TESTING\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We have elected to run a Vector Autoregressive analysis, the result is we had to manipulate the data to obtain stationarity in the variables.\n",
    "In order to obtain this we had to take the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%Exploratory analysis for Regression\n"
    }
   },
   "outputs": [],
   "source": [
    "df60 = dataframes[1960]\n",
    "corrmat_partial = df60.drop(columns=['country', 'year']).corr()\n",
    "\n",
    "corrmat_partial *= np.where(np.tri(*corrmat_partial.shape, k=-1) == 0, np.nan,\n",
    "                            1)  # puts NaN on upper triangular matrix, including diagonal (k=-1)\n",
    "corrmat = pd.get_dummies(df60).drop(columns=['year']).corr()\n",
    "corrmat_list = corrmat.unstack().to_frame()\n",
    "corrmat_list.columns = ['correlation']\n",
    "corrmat_list['abs_corr'] = corrmat_list.correlation.abs()\n",
    "corrmat_list.sort_values(by=['abs_corr'], ascending=False, na_position='last', inplace=True)\n",
    "# corrmat_list.drop(columns=['abs_corr']).head(10)\n",
    "\n",
    "sns.heatmap(corrmat_partial, cmap=\"YlGnBu\", linewidths=0.1)\n",
    "plt.show()\n",
    "\n",
    "# regression analysis\n",
    "# variable distribution and relation to net migration\n",
    "# all for 1960, can be changed (looped) for other years\n",
    "\n",
    "X = pd.get_dummies(df60.drop(columns=['Net migration', 'year']))\n",
    "y = df60['Net migration'].values\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(10, 20), constrained_layout=True)\n",
    "spec = gridspec.GridSpec(nrows=X.shape[1], ncols=2, figure=fig)\n",
    "\n",
    "for var_index, var in enumerate(X.columns):\n",
    "    ax_left = fig.add_subplot(spec[var_index, 0])\n",
    "    sns.distplot(X[var], ax=ax_left)\n",
    "    ax_left.set_title(var + ' distribution', fontsize=10)\n",
    "    ax_right = fig.add_subplot(spec[var_index, 1])\n",
    "    ax_right.scatter(X[var], y, marker='o')\n",
    "    ax_right.set_title('Net migration vs ' + var, fontsize=10)\n",
    "    ax_right.set_xlabel(var)\n",
    "    ax_right.set_ylabel('Net migration')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%Regression Analysis\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.distplot(y_train, label='train')\n",
    "sns.distplot(y_test, label='test')\n",
    "plt.title('Target variable distribution', fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get coefficients\n",
    "print('Intercept:', model.intercept_)\n",
    "print('Slope:', model.coef_)\n",
    "print(pd.DataFrame({'Variable': ['intercept'] + list(X.columns), 'Coefficient': [\"{0:.5f}\".format(v) for v in\n",
    "                                                                                 np.append(model.intercept_,\n",
    "                                                                                           model.coef_.flatten()).round(\n",
    "                                                                                     6)]}))\n",
    "\n",
    "# get fitted value on training set\n",
    "y_train_predicted = model.predict(X_train)\n",
    "\n",
    "# compare predictions\n",
    "print(pd.DataFrame({'True': y_train.flatten(), 'Predicted': y_train_predicted.flatten()}))\n",
    "\n",
    "# plot marginal models\n",
    "fig, ax = plt.subplots(math.ceil(X_train.shape[1] / 3), 3, figsize=(20, 10), constrained_layout=True)\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, var in enumerate(X_train.columns):\n",
    "    ax[i].scatter(X_train[var], y_train, color='gray')\n",
    "    X_train_univariate = pd.DataFrame(np.zeros(X_train.shape), columns=X_train.columns, index=X_train.index)\n",
    "    X_train_univariate[var] = X_train[var]\n",
    "    y_train_predicted_univariate = model.predict(X_train_univariate)\n",
    "    ax[i].plot(X_train[var], y_train_predicted_univariate + (y_train.mean() - y_train_predicted_univariate.mean()),\n",
    "               color='red', linewidth=2)\n",
    "    # y_train.mean()-y_train_predicted_univariate.mean() has been added only to center the line on the points\n",
    "    # what matters is the slope of the line as the intercept term cannot be \"shared\" among all univariate variables\n",
    "    ax[i].set_title('Net migration vs ' + var + ' - corr: ' + \\\n",
    "                    str(round(corrmat_list.loc[(var, 'Net migration'), 'correlation'] * 100)) + '%', fontsize=15)\n",
    "    ax[i].set_xlabel(var)\n",
    "    ax[i].set_ylabel('Net migration')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# boxplot showing variability for each variable for 1960/65 and is standardized.\n",
    "# Again, we can make a loop to run this for dif time periods\n",
    "def box_plot(df60, standardize=True):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    if standardize == True:\n",
    "        # standardize columns for better visualization\n",
    "        df60 = pd.DataFrame(preprocessing.StandardScaler().fit_transform(df60.values), columns=df60.columns)\n",
    "    fig = sns.boxplot(x='value', y='variable',\n",
    "                      data=pd.melt(df60.reset_index(), id_vars='index', value_vars=list(df60.columns)),\n",
    "                      orient='h')\n",
    "    fig.tick_params(labelsize=20)\n",
    "    fig.set_xlabel('')\n",
    "    fig.set_ylabel('')\n",
    "    if standardize == True:\n",
    "        fig.set_title('Standardized Variable Distribution\\nfor better visualization', fontsize=40)\n",
    "    df60 = pd.plotting.register_matplotlib_converters()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "Q1 = df60.quantile(0.2)\n",
    "Q3 = df60.quantile(0.8)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "dataset_outlier = df60[~((df60 < (Q1 - IQR)) | (df60 > (Q3 + IQR))).any(axis=1)]\n",
    "print('\\nData size reduced from {} to {}\\n'.format(df60.shape[0], dataset_outlier.shape[0]))\n",
    "box_plot(dataset_outlier)\n",
    "\n",
    "# simple scatter plot comparing migration and tas 1960/65\n",
    "# can be changed to show other 1 on 1 relationships\n",
    "\"\"\"x = df60.iloc[:,0].values.reshape(-1,1)\n",
    "y = df60.iloc[:,1].values.reshape(-1,1)\n",
    "\n",
    "plt.scatter(x, y, marker='o')\n",
    "plt.title('Net migration vs tas 1960')\n",
    "plt.xlabel('Net migration')\n",
    "plt.ylabel('tas')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
